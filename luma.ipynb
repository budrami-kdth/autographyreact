{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: {\"exec_info\": {\"queue_remaining\": 0}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# 서버의 ComfyUI API URL 설정\n",
    "url = \"http://127.0.0.1:8189/prompt\"  # 현재 사용 중인 엔드포인트\n",
    "\n",
    "# GET 요청을 보내어 엔드포인트 테스트\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt queued successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 서버의 ComfyUI API URL 설정\n",
    "server_address = \"http://127.0.0.1:8189\"\n",
    "url = f\"{server_address}/prompt\"\n",
    "\n",
    "# 워크플로우 JSON 로드\n",
    "with open(\"workflow_api.json\") as f:\n",
    "    workflow = json.load(f)\n",
    "\n",
    "# CLIPTextEncode 클래스를 찾아 프롬프트 수정\n",
    "for key, node in workflow.items():\n",
    "    if isinstance(node, dict) and node.get(\"class_type\") == \"CLIPTextEncode\":\n",
    "        node[\"inputs\"][\"text\"] = \"A futuristic cityscape with neon lights\"  # 새로운 프롬프트 설정\n",
    "\n",
    "# API 요청 데이터 구성\n",
    "data = {\n",
    "    \"prompt\": workflow\n",
    "}\n",
    "\n",
    "# API 요청 보내기\n",
    "response = requests.post(url, json=data)\n",
    "if response.status_code == 200:\n",
    "    print(\"Prompt queued successfully!\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from lumaai import LumaAI\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 가져오기\n",
    "api_key = os.getenv(\"LUMAAI_API_KEY\")\n",
    "\n",
    "# LumaAI 클라이언트 설정\n",
    "client = LumaAI(auth_token=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "File downloaded as d13be421-4a7c-49d4-8351-e342cc287cd8.mp4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from lumaai import LumaAI\n",
    "\n",
    "client = LumaAI()\n",
    "\n",
    "generation = client.generations.create(\n",
    "  prompt=\"A teddy bear in sunglasses playing electric guitar and dancing\",\n",
    ")\n",
    "completed = False\n",
    "while not completed:\n",
    "  generation = client.generations.get(id=generation.id)\n",
    "  if generation.state == \"completed\":\n",
    "    completed = True\n",
    "  elif generation.state == \"failed\":\n",
    "    raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "  print(\"Dreaming\")\n",
    "  time.sleep(3)\n",
    "\n",
    "video_url = generation.assets.video\n",
    "\n",
    "# download the video\n",
    "response = requests.get(video_url, stream=True)\n",
    "with open(f'{generation.id}.mp4', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(f\"File downloaded as {generation.id}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt queued successfully! Checking every 10 seconds for up to 1 minute to allow image generation...\n",
      "Waiting for image generation...\n",
      "Waiting for image generation...\n",
      "Waiting for image generation...\n",
      "Waiting for image generation...\n",
      "Waiting for image generation...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from lumaai import LumaAI\n",
    "from cloudinary import CloudinaryImage, config as cloudinary_config\n",
    "from cloudinary.uploader import upload as cloudinary_upload\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "api_key = os.getenv(\"LUMAAI_API_KEY\")\n",
    "\n",
    "# LumaAI 클라이언트 설정\n",
    "client = LumaAI(auth_token=api_key)\n",
    "\n",
    "# 서버의 ComfyUI API URL 설정\n",
    "server_address = \"http://127.0.0.1:8189\"\n",
    "comfy_url = f\"{server_address}/prompt\"\n",
    "\n",
    "# Cloudinary 설정\n",
    "cloudinary_config(\n",
    "    cloud_name='dantiosiz',\n",
    "    api_key='344612546963595',\n",
    "    api_secret='z6uJ4nMCrznoy9YYXPvRYytQDgg'\n",
    ")\n",
    "\n",
    "# ComfyUI 워크플로우 JSON 로드\n",
    "with open(\"workflow_api.json\") as f:\n",
    "    workflow = json.load(f)\n",
    "\n",
    "# CLIPTextEncode 클래스를 찾아 프롬프트 수정\n",
    "for key, node in workflow.items():\n",
    "    if isinstance(node, dict) and node.get(\"class_type\") == \"CLIPTextEncode\":\n",
    "        node[\"inputs\"][\"text\"] = \"A teddy bear in sunglasses playing electric guitar and dancing\"\n",
    "\n",
    "# ComfyUI API 요청 보내기\n",
    "response = requests.post(comfy_url, json={\"prompt\": workflow})\n",
    "if response.status_code == 200:\n",
    "    print(\"Prompt queued successfully! Checking every 10 seconds for up to 1 minute to allow image generation...\")\n",
    "\n",
    "    # 최대 1분 동안 10초 간격으로 상태 확인\n",
    "    image_data = None\n",
    "    for _ in range(6):  # 최대 6번 (10초 * 6 = 60초)\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # ComfyUI에서 이미지 데이터 가져오기\n",
    "        image_data_response = requests.get(f\"{server_address}/result/{response.json().get('task_id')}\")  # 'result' 경로와 'task_id'는 ComfyUI API 사양에 맞게 수정 필요\n",
    "        image_data = image_data_response.json().get('image_data') if image_data_response.status_code == 200 else None\n",
    "\n",
    "        if image_data:\n",
    "            print(\"Image generation completed!\")\n",
    "            break  # 이미지가 생성되면 즉시 루프 종료\n",
    "        else:\n",
    "            print(\"Waiting for image generation...\")\n",
    "\n",
    "    # 이미지 생성이 완료되었는지 확인 후 작업 진행\n",
    "    if image_data:\n",
    "        image_path = \"generated_image.png\"\n",
    "        \n",
    "        # base64 데이터를 로컬에 이미지로 저장\n",
    "        with open(image_path, \"wb\") as img_file:\n",
    "            img_file.write(base64.b64decode(image_data))\n",
    "        print(f\"Image saved locally at: {image_path}\")\n",
    "\n",
    "        # Cloudinary에 이미지 업로드\n",
    "        try:\n",
    "            upload_result = cloudinary_upload(image_path, public_id='test_image', overwrite=True)\n",
    "            cloudinary_url = CloudinaryImage('test_image').build_url(fetch_format='auto', quality='auto')\n",
    "            print(f\"Image URL on Cloudinary: {cloudinary_url}\")\n",
    "\n",
    "            # Luma API에 이미지 URL 전달하여 비디오 생성\n",
    "            generation = client.generations.create(\n",
    "                prompt=\"The person in the scene should have minimal movement, with gentle, subtle motions like breathing or slight head turns\",\n",
    "                keyframes={\n",
    "                    \"frame0\": {\n",
    "                        \"type\": \"image\",\n",
    "                        \"url\": cloudinary_url\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            completed = False\n",
    "            while not completed:\n",
    "                generation = client.generations.get(id=generation.id)\n",
    "                if generation.state == \"completed\":\n",
    "                    completed = True\n",
    "                    video_url = generation.assets.video\n",
    "\n",
    "                    # 비디오 다운로드\n",
    "                    video_response = requests.get(video_url, stream=True)\n",
    "                    video_path = f\"{generation.id}.mp4\"\n",
    "                    with open(video_path, 'wb') as video_file:\n",
    "                        for chunk in video_response.iter_content(chunk_size=1024):\n",
    "                            if chunk:\n",
    "                                video_file.write(chunk)\n",
    "                    print(f\"Video downloaded locally as {video_path}\")\n",
    "                elif generation.state == \"failed\":\n",
    "                    raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "                print(\"Generating animation...\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to upload image to Cloudinary or generate video:\", e)\n",
    "    else:\n",
    "        print(\"Error: Image was not generated within the 1-minute limit.\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URL on Cloudinary: http://res.cloudinary.com/dantiosiz/image/upload/f_auto,q_auto/test_image\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Generating animation...\n",
      "Video downloaded locally as beee8acd-9fe0-4f3b-b3fd-6e78129fae7b.mp4\n",
      "Generating animation...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from lumaai import LumaAI\n",
    "from cloudinary import CloudinaryImage, config as cloudinary_config\n",
    "from cloudinary.uploader import upload as cloudinary_upload\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "api_key = os.getenv(\"LUMAAI_API_KEY\")\n",
    "\n",
    "# LumaAI 클라이언트 설정\n",
    "client = LumaAI(auth_token=api_key)\n",
    "\n",
    "# Cloudinary 설정\n",
    "cloudinary_config(\n",
    "    cloud_name='dantiosiz',\n",
    "    api_key='344612546963595',\n",
    "    api_secret='z6uJ4nMCrznoy9YYXPvRYytQDgg'\n",
    ")\n",
    "\n",
    "# 로컬 이미지 파일 경로 설정\n",
    "local_image_path = \"ComfyUI_00042_.png\"  # 테스트할 로컬 이미지 파일 경로\n",
    "\n",
    "# Cloudinary에 이미지 업로드\n",
    "try:\n",
    "    # 로컬 이미지 업로드\n",
    "    upload_result = cloudinary_upload(local_image_path, public_id='test_image', overwrite=True)\n",
    "    cloudinary_url = CloudinaryImage('test_image').build_url(fetch_format='auto', quality='auto')\n",
    "    print(f\"Image URL on Cloudinary: {cloudinary_url}\")\n",
    "\n",
    "    # Luma API에 이미지 URL 전달하여 비디오 생성\n",
    "    generation = client.generations.create(\n",
    "        prompt=\"The person in the scene should have minimal movement, with gentle, subtle motions like breathing or slight head turns\",\n",
    "        keyframes={\n",
    "            \"frame0\": {\n",
    "                \"type\": \"image\",\n",
    "                \"url\": cloudinary_url\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    completed = False\n",
    "    while not completed:\n",
    "        generation = client.generations.get(id=generation.id)\n",
    "        if generation.state == \"completed\":\n",
    "            completed = True\n",
    "            video_url = generation.assets.video\n",
    "\n",
    "            # 비디오 다운로드\n",
    "            video_response = requests.get(video_url, stream=True)\n",
    "            video_path = f\"{generation.id}.mp4\"\n",
    "            with open(video_path, 'wb') as video_file:\n",
    "                for chunk in video_response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        video_file.write(chunk)\n",
    "            print(f\"Video downloaded locally as {video_path}\")\n",
    "        elif generation.state == \"failed\":\n",
    "            raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "        print(\"Generating animation...\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to upload image to Cloudinary or generate video:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from lumaai import LumaAI\n",
    "from cloudinary import CloudinaryImage, config as cloudinary_config\n",
    "from cloudinary.uploader import upload as cloudinary_upload\n",
    "import paramiko\n",
    "from scp import SCPClient\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "api_key = os.getenv(\"LUMAAI_API_KEY\")\n",
    "\n",
    "# LumaAI 클라이언트 설정\n",
    "client = LumaAI(auth_token=api_key)\n",
    "\n",
    "# Cloudinary 설정\n",
    "cloudinary_config(\n",
    "    cloud_name='dantiosiz',\n",
    "    api_key='344612546963595',\n",
    "    api_secret='z6uJ4nMCrznoy9YYXPvRYytQDgg'\n",
    ")\n",
    "\n",
    "# SSH 정보 설정\n",
    "ssh_server_ip = \"192.168.1.100\"  # Vast AI 서버 IP\n",
    "ssh_username = \"root\"\n",
    "ssh_key_path = \"/Users/travis/.ssh/id_direct_rsa\"\n",
    "remote_directory = \"/workspace/ComfyUI/output\"  # ComfyUI 출력 디렉토리\n",
    "local_directory = \"./images\"  # 로컬 저장 디렉토리\n",
    "os.makedirs(local_directory, exist_ok=True)\n",
    "\n",
    "def get_latest_file_path(remote_directory):\n",
    "    \"\"\"서버 디렉토리에서 가장 최근 파일 경로 반환\"\"\"\n",
    "    try:\n",
    "        ssh = paramiko.SSHClient()\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        ssh.connect(ssh_server_ip, username=ssh_username, key_filename=ssh_key_path)\n",
    "        \n",
    "        # 가장 최근 파일 경로 확인\n",
    "        stdin, stdout, stderr = ssh.exec_command(f\"ls -t {remote_directory} | head -n 1\")\n",
    "        latest_file = stdout.read().decode().strip()\n",
    "        if latest_file:\n",
    "            return f\"{remote_directory}/{latest_file}\"\n",
    "        else:\n",
    "            raise FileNotFoundError(\"No files found in the specified directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding latest file: {e}\")\n",
    "    finally:\n",
    "        ssh.close()\n",
    "\n",
    "\n",
    "def download_image_via_ssh(remote_path, local_path):\n",
    "    \"\"\"SSH를 통해 Vast AI 서버에서 파일 다운로드\"\"\"\n",
    "    try:\n",
    "        ssh = paramiko.SSHClient()\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        ssh.connect(ssh_server_ip, username=ssh_username, key_filename=ssh_key_path)\n",
    "\n",
    "        with SCPClient(ssh.get_transport()) as scp:\n",
    "            scp.get(remote_path, local_path)\n",
    "        print(f\"Image downloaded via SSH to: {local_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image via SSH: {e}\")\n",
    "    finally:\n",
    "        ssh.close()\n",
    "\n",
    "\n",
    "# ComfyUI 워크플로우 JSON 로드\n",
    "with open(\"workflow_api.json\") as f:\n",
    "    workflow = json.load(f)\n",
    "\n",
    "# CLIPTextEncode 클래스를 찾아 프롬프트 수정\n",
    "for key, node in workflow.items():\n",
    "    if isinstance(node, dict) and node.get(\"class_type\") == \"CLIPTextEncode\":\n",
    "        node[\"inputs\"][\"text\"] = \"A teddy bear in sunglasses playing electric guitar and dancing\"\n",
    "\n",
    "# 서버의 ComfyUI API URL 설정\n",
    "server_address = \"http://127.0.0.1:8189\"\n",
    "comfy_url = f\"{server_address}/prompt\"\n",
    "\n",
    "# ComfyUI API 요청 보내기\n",
    "response = requests.post(comfy_url, json={\"prompt\": workflow})\n",
    "if response.status_code == 200:\n",
    "    print(\"Prompt queued successfully! Checking every 10 seconds for up to 1 minute to allow image generation...\")\n",
    "\n",
    "    # 최대 1분 동안 10초 간격으로 상태 확인\n",
    "    task_id = response.json().get('task_id')  # ComfyUI에서 반환한 task_id 사용\n",
    "    for _ in range(6):  # 최대 6번 (10초 * 6 = 60초)\n",
    "        time.sleep(10)\n",
    "\n",
    "        # ComfyUI에서 상태 확인\n",
    "        status_response = requests.get(f\"{server_address}/status/{task_id}\")  # API 경로는 ComfyUI 사양에 맞게 수정\n",
    "        if status_response.status_code == 200 and status_response.json().get('status') == \"completed\":\n",
    "            print(\"Image generation completed!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Waiting for image generation...\")\n",
    "    else:\n",
    "        print(\"Error: Image was not generated within the 1-minute limit.\")\n",
    "        exit(1)\n",
    "\n",
    "    # 서버에서 최신 이미지 파일 경로 가져오기\n",
    "    remote_image_path = get_latest_file_path(remote_directory)\n",
    "    file_name = os.path.basename(remote_image_path)\n",
    "    local_image_path = os.path.join(local_directory, file_name)\n",
    "\n",
    "    # SSH로 서버에서 로컬로 이미지 다운로드\n",
    "    download_image_via_ssh(remote_image_path, local_image_path)\n",
    "\n",
    "    # Cloudinary에 이미지 업로드\n",
    "    try:\n",
    "        upload_result = cloudinary_upload(local_image_path, public_id='test_image', overwrite=True)\n",
    "        cloudinary_url = CloudinaryImage('test_image').build_url(fetch_format='auto', quality='auto')\n",
    "        print(f\"Image URL on Cloudinary: {cloudinary_url}\")\n",
    "\n",
    "        # Luma API에 이미지 URL 전달하여 비디오 생성\n",
    "        generation = client.generations.create(\n",
    "            prompt=\"The person in the scene should have minimal movement, with gentle, subtle motions like breathing or slight head turns\",\n",
    "            keyframes={\n",
    "                \"frame0\": {\n",
    "                    \"type\": \"image\",\n",
    "                    \"url\": cloudinary_url\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        completed = False\n",
    "        while not completed:\n",
    "            generation = client.generations.get(id=generation.id)\n",
    "            if generation.state == \"completed\":\n",
    "                completed = True\n",
    "                video_url = generation.assets.video\n",
    "\n",
    "                # 비디오 다운로드\n",
    "                video_response = requests.get(video_url, stream=True)\n",
    "                video_path = f\"{generation.id}.mp4\"\n",
    "                with open(video_path, 'wb') as video_file:\n",
    "                    for chunk in video_response.iter_content(chunk_size=1024):\n",
    "                        if chunk:\n",
    "                            video_file.write(chunk)\n",
    "                print(f\"Video downloaded locally as {video_path}\")\n",
    "            elif generation.state == \"failed\":\n",
    "                raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "            print(\"Generating animation...\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to upload image to Cloudinary or generate video:\", e)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\", response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comfyui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
